{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation System using Word2vec\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>show_id</th>\n",
       "      <th>title</th>\n",
       "      <th>listed_in</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s1</td>\n",
       "      <td>Dick Johnson Is Dead</td>\n",
       "      <td>Documentaries</td>\n",
       "      <td>As her father nears the end of his life, filmm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s2</td>\n",
       "      <td>Blood &amp; Water</td>\n",
       "      <td>International TV Shows, TV Dramas, TV Mysteries</td>\n",
       "      <td>After crossing paths at a party, a Cape Town t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s3</td>\n",
       "      <td>Ganglands</td>\n",
       "      <td>Crime TV Shows, International TV Shows, TV Act...</td>\n",
       "      <td>To protect his family from a powerful drug lor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  show_id                 title  \\\n",
       "0      s1  Dick Johnson Is Dead   \n",
       "1      s2         Blood & Water   \n",
       "2      s3             Ganglands   \n",
       "\n",
       "                                           listed_in  \\\n",
       "0                                      Documentaries   \n",
       "1    International TV Shows, TV Dramas, TV Mysteries   \n",
       "2  Crime TV Shows, International TV Shows, TV Act...   \n",
       "\n",
       "                                         description  \n",
       "0  As her father nears the end of his life, filmm...  \n",
       "1  After crossing paths at a party, a Cape Town t...  \n",
       "2  To protect his family from a powerful drug lor...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_netflix = pd.read_csv(\"./netflix_titles.csv\")\n",
    "df_netflix.drop(\n",
    "    columns=[\n",
    "        \"director\",\n",
    "        \"cast\",\n",
    "        \"country\",\n",
    "        \"date_added\",\n",
    "        \"release_year\",\n",
    "        \"rating\",\n",
    "        \"duration\",\n",
    "        \"type\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")\n",
    "df_netflix.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Punctuations and Stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df_netflix[\"title_list\"] = df_netflix[\"title\"].str.lower()\n",
    "df_netflix[\"listed_in\"] = df_netflix[\"listed_in\"].str.lower()\n",
    "df_netflix[\"description\"] = df_netflix[\"description\"].str.lower()\n",
    "\n",
    "df_netflix[\"title_list\"] = df_netflix[\"title_list\"].apply(word_tokenize)\n",
    "df_netflix[\"listed_in\"] = df_netflix[\"listed_in\"].apply(word_tokenize)\n",
    "df_netflix[\"description\"] = df_netflix[\"description\"].apply(word_tokenize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "\n",
    "list_stopwords = set(stopwords.words(\"english\") + list(punctuation))\n",
    "df_netflix[\"title_list\"] = df_netflix[\"title_list\"].apply(\n",
    "    lambda x: [word for word in x if word not in list_stopwords]\n",
    ")\n",
    "df_netflix[\"listed_in\"] = df_netflix[\"listed_in\"].apply(\n",
    "    lambda x: [word for word in x if word not in list_stopwords]\n",
    ")\n",
    "df_netflix[\"description\"] = df_netflix[\"description\"].apply(\n",
    "    lambda x: [word for word in x if word not in list_stopwords]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "df_netflix[\"description\"] = df_netflix[\"description\"].apply(\n",
    "    lambda x: [word.translate(str.maketrans(\"\", \"\", string.punctuation)) for word in x]\n",
    ")\n",
    "df_netflix[\"description\"] = df_netflix[\"description\"].apply(\n",
    "    lambda x: [word for word in x if len(word) > 0]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_netflix[\"title_list\"] = df_netflix[\"title_list\"].apply(lambda x: list(set(x)))\n",
    "df_netflix[\"listed_in\"] = df_netflix[\"listed_in\"].apply(lambda x: list(set(x)))\n",
    "df_netflix[\"description\"] = df_netflix[\"description\"].apply(lambda x: list(set(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
    "! gunzip GoogleNews-vectors-negative300.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "wv = gensim.models.KeyedVectors.load_word2vec_format(\n",
    "    \"./GoogleNews-vectors-negative300.bin\", binary=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Similarities Among Shows using Title, Genres, Description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_netflix_vocab = []\n",
    "for list_ in df_netflix.to_numpy():\n",
    "    list_[2] = [word for word in list_[2] if word in wv.key_to_index]\n",
    "    list_[3] = [word for word in list_[3] if word in wv.key_to_index]\n",
    "    list_[4] = [word for word in list_[4] if word in wv.key_to_index]\n",
    "    matrix_netflix_vocab.append(list_)\n",
    "df_netflix_vocab = pd.DataFrame(matrix_netflix_vocab, columns=df_netflix.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def recommendation(title):\n",
    "    matrix_netflix_title_vocab = []\n",
    "    for list_ in df_netflix[df_netflix[\"title\"] == title].to_numpy():\n",
    "        list_[2] = [word for word in list_[2] if word in wv.key_to_index]\n",
    "        list_[3] = [word for word in list_[3] if word in wv.key_to_index]\n",
    "        list_[4] = [word for word in list_[4] if word in wv.key_to_index]\n",
    "        matrix_netflix_title_vocab.append(list_)\n",
    "\n",
    "    matrix_similarity = []\n",
    "    pbar = tqdm(matrix_netflix_vocab)\n",
    "    for list1 in pbar:\n",
    "        for list2 in matrix_netflix_title_vocab:\n",
    "            score_catg = wv.n_similarity(list1[2], list2[2])\n",
    "            score_desc = wv.n_similarity(list1[3], list2[3])\n",
    "            try:\n",
    "                score_title = wv.n_similarity(list1[4], list2[4]) / 2\n",
    "            except:\n",
    "                score_title = 0\n",
    "            if (list1[1] != list2[1]) & (score_catg > 0.85):\n",
    "                matrix_similarity.append(\n",
    "                    [list1[1], list2[1], score_title, score_catg, score_desc]\n",
    "                )\n",
    "        pbar.update()\n",
    "    pbar.close()\n",
    "    df_netflix_similarity = pd.DataFrame(\n",
    "        matrix_similarity,\n",
    "        columns=[\n",
    "            \"recommendation\",\n",
    "            \"title\",\n",
    "            \"score_title\",\n",
    "            \"score_category\",\n",
    "            \"score_description\",\n",
    "        ],\n",
    "    )\n",
    "    df_netflix_similarity[\"final_score\"] = (\n",
    "        df_netflix_similarity[\"score_title\"]\n",
    "        + df_netflix_similarity[\"score_category\"]\n",
    "        + df_netflix_similarity[\"score_description\"]\n",
    "    )\n",
    "    return df_netflix_similarity.sort_values(\n",
    "        by=[\"final_score\", \"score_category\", \"score_description\", \"score_title\"],\n",
    "        ascending=False,\n",
    "    ).head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Recommender using word2vec tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8807/8807 [00:05<00:00, 1692.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommendation</th>\n",
       "      <th>title</th>\n",
       "      <th>score_title</th>\n",
       "      <th>score_category</th>\n",
       "      <th>score_description</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>Conjuring Spirit</td>\n",
       "      <td>The Conjuring</td>\n",
       "      <td>0.376218</td>\n",
       "      <td>0.964287</td>\n",
       "      <td>0.624534</td>\n",
       "      <td>1.965039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>The Conjuring 2</td>\n",
       "      <td>The Conjuring</td>\n",
       "      <td>0.408480</td>\n",
       "      <td>0.913295</td>\n",
       "      <td>0.595724</td>\n",
       "      <td>1.917499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>Delirium</td>\n",
       "      <td>The Conjuring</td>\n",
       "      <td>0.111870</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.687572</td>\n",
       "      <td>1.799442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Insidious</td>\n",
       "      <td>The Conjuring</td>\n",
       "      <td>0.093044</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.687981</td>\n",
       "      <td>1.781025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>The Diabolical</td>\n",
       "      <td>The Conjuring</td>\n",
       "      <td>0.156948</td>\n",
       "      <td>0.953485</td>\n",
       "      <td>0.669266</td>\n",
       "      <td>1.779699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>The Strange House</td>\n",
       "      <td>The Conjuring</td>\n",
       "      <td>0.086246</td>\n",
       "      <td>0.964287</td>\n",
       "      <td>0.713428</td>\n",
       "      <td>1.763960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>The Haunting of Molly Hartley</td>\n",
       "      <td>The Conjuring</td>\n",
       "      <td>0.173505</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.572111</td>\n",
       "      <td>1.745615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>All Light Will End</td>\n",
       "      <td>The Conjuring</td>\n",
       "      <td>0.097360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.641380</td>\n",
       "      <td>1.738740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Malevolent</td>\n",
       "      <td>The Conjuring</td>\n",
       "      <td>0.147643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.585509</td>\n",
       "      <td>1.733152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>The Strangers</td>\n",
       "      <td>The Conjuring</td>\n",
       "      <td>0.073289</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.645084</td>\n",
       "      <td>1.718374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    recommendation          title  score_title  \\\n",
       "383               Conjuring Spirit  The Conjuring     0.376218   \n",
       "95                 The Conjuring 2  The Conjuring     0.408480   \n",
       "391                       Delirium  The Conjuring     0.111870   \n",
       "86                       Insidious  The Conjuring     0.093044   \n",
       "513                 The Diabolical  The Conjuring     0.156948   \n",
       "64               The Strange House  The Conjuring     0.086246   \n",
       "522  The Haunting of Molly Hartley  The Conjuring     0.173505   \n",
       "355             All Light Will End  The Conjuring     0.097360   \n",
       "273                     Malevolent  The Conjuring     0.147643   \n",
       "42                   The Strangers  The Conjuring     0.073289   \n",
       "\n",
       "     score_category  score_description  final_score  \n",
       "383        0.964287           0.624534     1.965039  \n",
       "95         0.913295           0.595724     1.917499  \n",
       "391        1.000000           0.687572     1.799442  \n",
       "86         1.000000           0.687981     1.781025  \n",
       "513        0.953485           0.669266     1.779699  \n",
       "64         0.964287           0.713428     1.763960  \n",
       "522        1.000000           0.572111     1.745615  \n",
       "355        1.000000           0.641380     1.738740  \n",
       "273        1.000000           0.585509     1.733152  \n",
       "42         1.000000           0.645084     1.718374  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendation(\"The Conjuring\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8807/8807 [00:04<00:00, 1792.22it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recommendation</th>\n",
       "      <th>title</th>\n",
       "      <th>score_title</th>\n",
       "      <th>score_category</th>\n",
       "      <th>score_description</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>What Lies Below</td>\n",
       "      <td>Insidious</td>\n",
       "      <td>0.112808</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.807122</td>\n",
       "      <td>1.919930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>The Diabolical</td>\n",
       "      <td>Insidious</td>\n",
       "      <td>0.260919</td>\n",
       "      <td>0.953485</td>\n",
       "      <td>0.690771</td>\n",
       "      <td>1.905174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Malevolent</td>\n",
       "      <td>Insidious</td>\n",
       "      <td>0.247639</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.624875</td>\n",
       "      <td>1.872514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>The Devil Inside</td>\n",
       "      <td>Insidious</td>\n",
       "      <td>0.141939</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.695405</td>\n",
       "      <td>1.837343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>The Haunting of Molly Hartley</td>\n",
       "      <td>Insidious</td>\n",
       "      <td>0.146591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.677317</td>\n",
       "      <td>1.823909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Things Heard &amp; Seen</td>\n",
       "      <td>Insidious</td>\n",
       "      <td>0.082905</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.726047</td>\n",
       "      <td>1.808952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>Bhoot</td>\n",
       "      <td>Insidious</td>\n",
       "      <td>0.084453</td>\n",
       "      <td>0.964287</td>\n",
       "      <td>0.753416</td>\n",
       "      <td>1.802156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>The Strange House</td>\n",
       "      <td>Insidious</td>\n",
       "      <td>0.105459</td>\n",
       "      <td>0.964287</td>\n",
       "      <td>0.728778</td>\n",
       "      <td>1.798524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>Delirium</td>\n",
       "      <td>Insidious</td>\n",
       "      <td>0.050422</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.745601</td>\n",
       "      <td>1.796024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>Sinister 2</td>\n",
       "      <td>Insidious</td>\n",
       "      <td>0.223022</td>\n",
       "      <td>0.913295</td>\n",
       "      <td>0.656998</td>\n",
       "      <td>1.793315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    recommendation      title  score_title  score_category  \\\n",
       "84                 What Lies Below  Insidious     0.112808        1.000000   \n",
       "513                 The Diabolical  Insidious     0.260919        0.953485   \n",
       "273                     Malevolent  Insidious     0.247639        1.000000   \n",
       "512               The Devil Inside  Insidious     0.141939        1.000000   \n",
       "522  The Haunting of Molly Hartley  Insidious     0.146591        1.000000   \n",
       "72             Things Heard & Seen  Insidious     0.082905        1.000000   \n",
       "370                          Bhoot  Insidious     0.084453        0.964287   \n",
       "64               The Strange House  Insidious     0.105459        0.964287   \n",
       "391                       Delirium  Insidious     0.050422        1.000000   \n",
       "223                     Sinister 2  Insidious     0.223022        0.913295   \n",
       "\n",
       "     score_description  final_score  \n",
       "84            0.807122     1.919930  \n",
       "513           0.690771     1.905174  \n",
       "273           0.624875     1.872514  \n",
       "512           0.695405     1.837343  \n",
       "522           0.677317     1.823909  \n",
       "72            0.726047     1.808952  \n",
       "370           0.753416     1.802156  \n",
       "64            0.728778     1.798524  \n",
       "391           0.745601     1.796024  \n",
       "223           0.656998     1.793315  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendation(\"Insidious\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation System using Node2vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx  # create and store graph\n",
    "from node2vec import Node2Vec  # To run node2vec algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_node2vec = pd.read_csv(\"./netflix_titles.csv\")\n",
    "df_node2vec = df_node2vec.dropna()\n",
    "df_node2vec.drop(\n",
    "    columns=[\n",
    "        \"director\",\n",
    "        \"cast\",\n",
    "        \"country\",\n",
    "        \"date_added\",\n",
    "        \"release_year\",\n",
    "        \"rating\",\n",
    "        \"duration\",\n",
    "        \"type\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and analyzing Graph\n",
    "\n",
    "Now, we'll use networkx to create a graph with movie titles and genres as nodes. I used two different functions: -\n",
    "\n",
    "- addToGraph(movie name, graph): Adds an edge to the graph with the title and genres as nodes.\n",
    "- createGraph(): This function calls addToGraph for each movie title in order to generate a complete graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that will create edges for given movie title and its genres\n",
    "def addToGraph(movie_name, graph):\n",
    "    genres = (\n",
    "        df_node2vec[df_node2vec[\"title\"] == movie_name][\"listed_in\"]\n",
    "        .values[0]\n",
    "        .rstrip()\n",
    "        .lower()\n",
    "        .split(\", \")\n",
    "    )\n",
    "    for genre in genres:\n",
    "        graph.add_edge(movie_name.strip(), genre)\n",
    "    return graph\n",
    "\n",
    "\n",
    "# function that will create graph for all the movies name\n",
    "def createGraph():\n",
    "    graph = nx.Graph()\n",
    "    for movie_name in df_node2vec[\"title\"]:\n",
    "        graph = addToGraph(movie_name, graph)\n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = createGraph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# should be 2 since two genres are associated with it\n",
    "print(graph.degree()[\"Norm of the North: King Sized Adventure\"])\n",
    "# should be 1 since 1 genres are associated with it\n",
    "print(graph.degree()[\"#realityhigh\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Node2Vec\n",
    "\n",
    "Node2vec’s sampling strategy, accepts 4 arguments:\n",
    "\n",
    "- Number of walks: Number of random walks to be generated from each node in the graph\n",
    "- dimensions : Embedding dimensions\n",
    "- Walk length: How many nodes are in each random walk\n",
    "- P: Return hyperparameter\n",
    "- Q: Input hyperparameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|██████████| 5373/5373 [01:30<00:00, 59.42it/s] \n",
      "Generating walks (CPU: 1): 100%|██████████| 10/10 [01:31<00:00,  9.14s/it]\n"
     ]
    }
   ],
   "source": [
    "node2vec = Node2Vec(graph, dimensions=20, walk_length=16, num_walks=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = node2vec.fit(window=5, min_count=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See Embeddings\n",
    "\n",
    "Let's take a look at the values in embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3976648 ,  0.23961946, -0.3167309 , -0.12880409,  0.64077073,\n",
       "        0.32492435,  0.4883481 ,  0.818047  , -0.685554  ,  0.16029502,\n",
       "        0.5909224 , -0.2599521 ,  0.72134477,  0.5065936 ,  0.04392775,\n",
       "        0.5673693 ,  0.9184569 ,  0.13751492, -1.3321538 , -0.5747292 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.get_vector(\"The Conjuring\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2840743 ,  0.38807532, -0.4549778 , -0.06669122,  0.5805604 ,\n",
       "        0.37350893,  0.47478074,  0.99944   , -0.41174024,  0.16872013,\n",
       "        0.6267749 , -0.44709772,  0.80438036,  0.6019174 , -0.09264741,\n",
       "        0.3447448 ,  0.7417309 ,  0.13352576, -1.203107  , -0.8766482 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.get_vector(\"Insidious\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Node2Vec Embeddings\n",
    "\n",
    "We will use the generated embeddings to recommend similar genres and movies.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate similar movies to given genre or title\n",
    "def node2vec_recommender(name):\n",
    "    for node, _ in model.wv.most_similar(name):\n",
    "        print(node)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Recommender using node2vec tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Vatican Tapes\n",
      "Incarnate\n",
      "The Silence\n",
      "Green Room\n",
      "Gothika\n",
      "Malevolent\n",
      "Gehenna: Where Death Lives\n",
      "The Strangers\n",
      "Stonehearst Asylum\n",
      "Havenhurst\n"
     ]
    }
   ],
   "source": [
    "node2vec_recommender(\"Insidious\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Bye Bye Man\n",
      "Clinical\n",
      "Cabin Fever\n",
      "The Ring\n",
      "Stonehearst Asylum\n",
      "What Lies Beneath\n",
      "Death Note\n",
      "The Charnel House\n",
      "In the Tall Grass\n",
      "The Craft\n"
     ]
    }
   ],
   "source": [
    "node2vec_recommender(\"The Conjuring\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation System using Sentence Transformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load csv into Pandas Dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_df = pd.read_csv(\"./netflix_titles.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a sentence-transformers model: It maps sentences & paragraphs to a 768 dimensional dense vector space and can be used for tasks like clustering or semantic search.\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"paraphrase-distilroberta-base-v1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Embeddings for all show descriptions in dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions = sent_df[\"description\"].tolist()\n",
    "# print(descriptions)\n",
    "des_embeddings = []\n",
    "for i, des in enumerate(descriptions):\n",
    "    des_embeddings.append(model.encode(des))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For a query show_id let's find the top ten shows with the highest cosine similarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sentence_transformers import util\n",
    "\n",
    "\n",
    "def recommend(query):\n",
    "    query_embedded = model.encode(query)\n",
    "    cosine_scores = util.pytorch_cos_sim(query_embedded, des_embeddings)\n",
    "    top10_matches = torch.argsort(cosine_scores, dim=-1, descending=True).tolist()[0][\n",
    "        1:11\n",
    "    ]\n",
    "    return top10_matches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Recommender using sentence transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"The Conjuring\"\n",
    "query_show_des = sent_df.loc[sent_df[\"title\"] == title][\"description\"].to_list()[0]\n",
    "\n",
    "recommended_results = recommend(query_show_des)\n",
    "recommended_results = [x + 1 for x in recommended_results]\n",
    "\n",
    "for i in range(len(recommended_results)):\n",
    "    print(\n",
    "        sent_df[\"title\"].loc[\n",
    "            sent_df[\"show_id\"] == str(\"s\" + str(recommended_results[i]))\n",
    "        ]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation System using Cosine Similarity and TF-IDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cosine = pd.read_csv(\"../netflix_titles.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# removing stopwords\n",
    "tfidf = TfidfVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Replace NaN with an empty string\n",
    "df_cosine[\"description\"] = df_cosine[\"description\"].fillna(\"\")\n",
    "\n",
    "# Construct the required TF-IDF matrix by fitting and transforming the data\n",
    "tfidf_matrix = tfidf.fit_transform(df_cosine[\"description\"])\n",
    "\n",
    "# Output the shape of tfidf_matrix\n",
    "tfidf_matrix.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import linear_kernel\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "indices = pd.Series(df_cosine.index, index=df_cosine[\"title\"]).drop_duplicates()\n",
    "\n",
    "filledna = df_cosine.fillna(\"\")\n",
    "filledna.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning the data - making all the words lower case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(x):\n",
    "    return str.lower(x.replace(\" \", \"\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifying features on which the model is to be filtered.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"title\", \"director\", \"cast\", \"listed_in\", \"description\"]\n",
    "filledna = filledna[features]\n",
    "\n",
    "for feature in features:\n",
    "    filledna[feature] = filledna[feature].apply(clean_data)\n",
    "\n",
    "filledna.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a \"soup\" or a \"bag of words\" for all rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_soup(x):\n",
    "    return (\n",
    "        x[\"title\"]\n",
    "        + \" \"\n",
    "        + x[\"director\"]\n",
    "        + \" \"\n",
    "        + x[\"cast\"]\n",
    "        + \" \"\n",
    "        + x[\"listed_in\"]\n",
    "        + \" \"\n",
    "        + x[\"description\"]\n",
    "    )\n",
    "\n",
    "\n",
    "filledna[\"soup\"] = filledna.apply(create_soup, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "count = CountVectorizer(stop_words=\"english\")\n",
    "count_matrix = count.fit_transform(filledna[\"soup\"])\n",
    "\n",
    "cosine_sim2 = cosine_similarity(count_matrix, count_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filledna = filledna.reset_index()\n",
    "indices = pd.Series(filledna.index, index=filledna[\"title\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations_new(title, cosine_sim=cosine_sim):\n",
    "    title = title.replace(\" \", \"\").lower()\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Get the pairwsie similarity scores of all movies with that movie\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 10 most similar movies\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # Get the movie indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar movies\n",
    "    return df_cosine[\"title\"].iloc[movie_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_recommendations_new(\"The Conjuring\", cosine_sim2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation System using MiniBatchKMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import numpy as np # linear algebra\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysing the input dataframe\n",
    "df = pd.read_csv(\"../netflix_titles.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8271d315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping the multiple value cells into list type\n",
    "df[\"directors\"] = df[\"director\"].apply(\n",
    "    lambda l: [] if pd.isna(l) else [i.strip().replace(\" \", \"_\") for i in l.split(\",\")]\n",
    ")\n",
    "df[\"genres\"] = df[\"listed_in\"].apply(\n",
    "    lambda l: [] if pd.isna(l) else [i.strip().replace(\" \", \"_\") for i in l.split(\",\")]\n",
    ")\n",
    "df[\"actors\"] = df[\"cast\"].apply(\n",
    "    lambda l: [] if pd.isna(l) else [i.strip().replace(\" \", \"_\") for i in l.split(\",\")]\n",
    ")\n",
    "df[\"countries\"] = df[\"country\"].apply(\n",
    "    lambda l: [] if pd.isna(l) else [i.strip().replace(\" \", \"_\") for i in l.split(\",\")]\n",
    ")\n",
    "df[\"all_features\"] = df[\"directors\"] + df[\"genres\"] + df[\"actors\"] + df[\"countries\"]\n",
    "df[\"all_features\"] = df[\"all_features\"].apply(lambda x: \" \".join(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleanser(text):\n",
    "    stemmer = WordNetLemmatizer()\n",
    "    text = \"\".join(\n",
    "        [char for char in text if (char.isalpha() or char.isspace()) and char != \"'\"]\n",
    "    )\n",
    "    text = [\n",
    "        word.lower()\n",
    "        for word in text.split()\n",
    "        if word.lower() not in stopwords.words(\"english\")\n",
    "    ]\n",
    "    return [stemmer.lemmatize(word) for word in text]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc = df[[\"show_id\", \"description\"]].set_index(\"show_id\")\n",
    "df_desc[\"trunc_desc\"] = df_desc[\"description\"].apply(lambda x: text_cleanser(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = {}\n",
    "for words in df_desc.trunc_desc:\n",
    "    for word in words:\n",
    "        if word in vocabulary:\n",
    "            vocabulary[word] = vocabulary[word] + 1\n",
    "        else:\n",
    "            vocabulary[word] = 1\n",
    "df_voc = pd.DataFrame(list(vocabulary.items()), columns=[\"text\", \"count\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea0d7a4",
   "metadata": {
    "papermill": {
     "duration": 0.083573,
     "end_time": "2021-08-19T04:47:22.682055",
     "exception": false,
     "start_time": "2021-08-19T04:47:22.598482",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Clustering :-\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa476d5a",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-08-19T04:47:22.854673Z",
     "iopub.status.busy": "2021-08-19T04:47:22.854014Z",
     "iopub.status.idle": "2021-08-19T04:48:13.140424Z",
     "shell.execute_reply": "2021-08-19T04:48:13.141034Z",
     "shell.execute_reply.started": "2021-08-19T04:19:31.256718Z"
    },
    "papermill": {
     "duration": 50.377212,
     "end_time": "2021-08-19T04:48:13.141226",
     "exception": false,
     "start_time": "2021-08-19T04:47:22.764014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "bow_transformer = CountVectorizer(analyzer=text_cleanser).fit(df_desc[\"description\"])\n",
    "desc_bow = bow_transformer.transform(df_desc[\"description\"])\n",
    "print(\"Shape of the generated matrix : \", desc_bow.shape)\n",
    "sparsity = desc_bow.nnz / (desc_bow.shape[0] * desc_bow.shape[1]) * 100.0\n",
    "print(\"Sparsity of the generated matrix\", round(sparsity, 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21691317",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-08-19T04:48:13.581508Z",
     "iopub.status.busy": "2021-08-19T04:48:13.544667Z",
     "iopub.status.idle": "2021-08-19T04:48:13.854648Z",
     "shell.execute_reply": "2021-08-19T04:48:13.853493Z",
     "shell.execute_reply.started": "2021-08-19T04:20:22.103176Z"
    },
    "papermill": {
     "duration": 0.420597,
     "end_time": "2021-08-19T04:48:13.854834",
     "exception": false,
     "start_time": "2021-08-19T04:48:13.434237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Finding TF and IDF metrics\n",
    "vector = TfidfVectorizer(\n",
    "    max_df=1,\n",
    "    min_df=1,\n",
    "    strip_accents=\"ascii\",\n",
    "    stop_words=\"english\",\n",
    "    lowercase=True,\n",
    "    use_idf=True,\n",
    "    norm=\"l2\",\n",
    "    smooth_idf=True,\n",
    ")\n",
    "tfidf = vector.fit_transform(df.all_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725dbfd0",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-08-19T04:48:14.032099Z",
     "iopub.status.busy": "2021-08-19T04:48:14.031347Z",
     "iopub.status.idle": "2021-08-19T04:48:27.734143Z",
     "shell.execute_reply": "2021-08-19T04:48:27.733491Z",
     "shell.execute_reply.started": "2021-08-19T04:20:22.477706Z"
    },
    "papermill": {
     "duration": 13.79437,
     "end_time": "2021-08-19T04:48:27.734316",
     "exception": false,
     "start_time": "2021-08-19T04:48:13.939946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cluster the description data using MiniBatchKMeans\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# setting the no. of resulting clusters for kmeans\n",
    "k = 400\n",
    "kmeans = MiniBatchKMeans(n_clusters=k, init=\"k-means++\")\n",
    "kmeans.fit(tfidf)\n",
    "centers = kmeans.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vector.get_feature_names_out()\n",
    "request_transform = vector.transform(df[\"all_features\"])\n",
    "# new column cluster based on the description\n",
    "df[\"cluster\"] = kmeans.predict(request_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db07ae5",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-08-19T04:48:28.075694Z",
     "iopub.status.busy": "2021-08-19T04:48:28.074949Z",
     "iopub.status.idle": "2021-08-19T04:48:28.078955Z",
     "shell.execute_reply": "2021-08-19T04:48:28.078391Z",
     "shell.execute_reply.started": "2021-08-19T04:20:36.407627Z"
    },
    "papermill": {
     "duration": 0.095157,
     "end_time": "2021-08-19T04:48:28.079108",
     "exception": false,
     "start_time": "2021-08-19T04:48:27.983951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_similar_movies(tfidf_matrix, index, top_n=5):\n",
    "    cosine_similarities = linear_kernel(\n",
    "        tfidf_matrix[index : index + 1], tfidf_matrix\n",
    "    ).flatten()\n",
    "    related_docs_indices = [\n",
    "        i for i in cosine_similarities.argsort()[::-1] if i != index\n",
    "    ]\n",
    "    return [index for index in related_docs_indices][0:top_n]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da505d60",
   "metadata": {},
   "source": [
    "## Graph preparation\n",
    "\n",
    "- Insert all the notable parameters like castings,genre and directors as nodes in the graph.\n",
    "- use find_similar_movies() method to fetch the n related movies for the given node\n",
    "- Connect the all the related movie nodes with the selected movie with an edge names 'SIMILAR'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042488c8",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-08-19T04:48:28.613921Z",
     "iopub.status.busy": "2021-08-19T04:48:28.613225Z",
     "iopub.status.idle": "2021-08-19T04:49:40.156508Z",
     "shell.execute_reply": "2021-08-19T04:49:40.157089Z",
     "shell.execute_reply.started": "2021-08-19T04:20:36.448335Z"
    },
    "papermill": {
     "duration": 71.632149,
     "end_time": "2021-08-19T04:49:40.157311",
     "exception": false,
     "start_time": "2021-08-19T04:48:28.525162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "G = nx.Graph(label=\"MOVIE\")\n",
    "start_time = time.time()\n",
    "for i, rowi in df.iterrows():\n",
    "    G.add_node(\n",
    "        rowi[\"title\"],\n",
    "        key=rowi[\"show_id\"],\n",
    "        label=\"MOVIE\",\n",
    "        mtype=rowi[\"type\"],\n",
    "        rating=rowi[\"rating\"],\n",
    "    )\n",
    "    for element in rowi[\"actors\"]:\n",
    "        G.add_node(element, label=\"PERSON\")\n",
    "        G.add_edge(rowi[\"title\"], element, label=\"ACTED_IN\")\n",
    "    for element in rowi[\"genres\"]:\n",
    "        G.add_node(element, label=\"GENRE\")\n",
    "        G.add_edge(rowi[\"title\"], element, label=\"GENRE_IN\")\n",
    "    for element in rowi[\"directors\"]:\n",
    "        G.add_node(element, label=\"PERSON\")\n",
    "        G.add_edge(rowi[\"title\"], element, label=\"DIRECTED\")\n",
    "    for element in rowi[\"countries\"]:\n",
    "        G.add_node(element, label=\"COU\")\n",
    "        G.add_edge(rowi[\"title\"], element, label=\"COU_IN\")\n",
    "\n",
    "    indices = find_similar_movies(tfidf, i, top_n=3)\n",
    "    snode = \"Sim(\" + rowi[\"title\"][:15].strip() + \")\"\n",
    "    G.add_node(snode, label=\"SIMILAR\")\n",
    "    G.add_edge(rowi[\"title\"], snode, label=\"SIMILARITY\")\n",
    "    for element in indices:\n",
    "        G.add_edge(snode, df[\"title\"].loc[element], label=\"SIMILARITY\")\n",
    "print(\" finish -- {} seconds --\".format(time.time() - start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1060229b",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-08-19T04:49:40.335035Z",
     "iopub.status.busy": "2021-08-19T04:49:40.334307Z",
     "iopub.status.idle": "2021-08-19T04:49:40.347223Z",
     "shell.execute_reply": "2021-08-19T04:49:40.347861Z",
     "shell.execute_reply.started": "2021-08-19T04:45:04.594382Z"
    },
    "papermill": {
     "duration": 0.105613,
     "end_time": "2021-08-19T04:49:40.348073",
     "exception": false,
     "start_time": "2021-08-19T04:49:40.242460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_all_adj_nodes(list_in):\n",
    "    sub_graph = set()\n",
    "    for m in list_in:\n",
    "        sub_graph.add(m)\n",
    "        for e in G.neighbors(m):\n",
    "            sub_graph.add(e)\n",
    "    return list(sub_graph)\n",
    "\n",
    "\n",
    "def draw_sub_graph(sub_graph, title=\"\"):\n",
    "    subgraph = G.subgraph(sub_graph)\n",
    "    colors = []\n",
    "    sizes = []\n",
    "    std_size = 500\n",
    "    for e in subgraph.nodes():\n",
    "        if G.nodes[e][\"label\"] == \"MOVIE\":\n",
    "            colors.append(\"#b3042c\")\n",
    "            sizes.append(std_size * 5)\n",
    "        elif G.nodes[e][\"label\"] == \"PERSON\":\n",
    "            colors.append(\"#047d59\")\n",
    "            sizes.append(std_size * 2.5)\n",
    "        elif G.nodes[e][\"label\"] == \"GENRE\":\n",
    "            colors.append(\"#3a018a\")\n",
    "            sizes.append(std_size)\n",
    "        elif G.nodes[e][\"label\"] == \"COU\":\n",
    "            colors.append(\"#bd3102\")\n",
    "            sizes.append(std_size * 0.9)\n",
    "        elif G.nodes[e][\"label\"] == \"SIMILAR\":\n",
    "            colors.append(\"#b87906\")\n",
    "            sizes.append(std_size)\n",
    "        elif G.nodes[e][\"label\"] == \"CLUSTER\":\n",
    "            colors.append(\"#cdf7e9\")\n",
    "            sizes.append(std_size * 0.9)\n",
    "    fig, ax = plt.subplots(figsize=(18, 18))\n",
    "    nx.draw(\n",
    "        subgraph,\n",
    "        with_labels=True,\n",
    "        alpha=0.8,\n",
    "        node_shape=\"o\",\n",
    "        node_size=sizes,\n",
    "        cmap=\"Accent\",\n",
    "        edge_color=\"white\",\n",
    "        font_color=\"white\",\n",
    "        font_weight=\"bold\",\n",
    "        node_color=colors,\n",
    "    )\n",
    "    # plt.title('Recommendations after watching The video '+title+' :-')\n",
    "    ax.set_title(\"Recommendations for Movie \" + title + \" :-\", color=\"white\", size=30)\n",
    "    ax.axis(\"off\")\n",
    "    fig.set_facecolor(\"#44495c\")\n",
    "    plt.tight_layout()\n",
    "    plt.gcf().set_dpi(400)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d55dc9",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2021-08-19T04:49:40.697207Z",
     "iopub.status.busy": "2021-08-19T04:49:40.696515Z",
     "iopub.status.idle": "2021-08-19T04:49:40.705198Z",
     "shell.execute_reply": "2021-08-19T04:49:40.705887Z",
     "shell.execute_reply.started": "2021-08-19T04:32:24.636325Z"
    },
    "papermill": {
     "duration": 0.098554,
     "end_time": "2021-08-19T04:49:40.706121",
     "exception": false,
     "start_time": "2021-08-19T04:49:40.607567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_recommendation(root):\n",
    "    commons_dict = {}\n",
    "    for e in G.neighbors(root):\n",
    "        for e2 in G.neighbors(e):\n",
    "            if e2 == root:\n",
    "                continue\n",
    "            if G.nodes[e2][\"label\"] == \"MOVIE\":\n",
    "                commons = commons_dict.get(e2)\n",
    "                if commons == None:\n",
    "                    commons_dict.update({e2: [e]})\n",
    "                else:\n",
    "                    commons.append(e)\n",
    "                    commons_dict.update({e2: commons})\n",
    "    movies = []\n",
    "    weight = []\n",
    "    for key, values in commons_dict.items():\n",
    "        w = 0.0\n",
    "        for e in values:\n",
    "            w = w + 1 / math.log(G.degree(e))\n",
    "        movies.append(key)\n",
    "        weight.append(w)\n",
    "\n",
    "    result = pd.Series(data=np.array(weight), index=movies)\n",
    "    result.sort_values(inplace=True, ascending=False)\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Movie = \"Dark\"\n",
    "recommendation = get_recommendation(Movie)\n",
    "rel_graph = get_all_adj_nodes([Movie] + list(recommendation.index[:2]))\n",
    "draw_sub_graph(rel_graph, Movie)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
